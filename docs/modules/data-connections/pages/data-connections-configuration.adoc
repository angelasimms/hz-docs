[[configuring-connections-to-external-data-stores]]
= Configuring Data Connections to External Systems
:description: A data connection contains the metadata that Hazelcast needs to connect an external system. You can define a data connection in your members' configuration files, in the Java member API, or in SQL, and reuse the same connection details in the Pipeline API, SQL mappings, and MapStores.   
:page-beta: true
:page-aliases: external-data-stores:external-data-stores.adoc, data-links:configuring-connections.adoc

{description}

== Quickstart Configuration

To configure a data connection to an external system, you must do the following:

* Provide a unique identifier (`name`) for the data connection.
* Choose the correct type of data connection for your external system. 

See examples for other <<configuration-options, connection properties>> for each data connection type.

=== Example JDBC Data Connection

This example configuration shows a data connection to a MySQL database using a JDBC connection.

[tabs]
====
XML::
+
--
[source,xml]
----
<hazelcast>
  <data-connection name="my-mysql-database">
    <type>JDBC</type>
    <properties>
      <property name="jdbcUrl">jdbc:mysql://mysql.example.org:3306</property> <1>
      <property name="user">my_user</property> <2>
      <property name="password">my_password</property>
    </properties>
    <shared>true</shared>
  </data-connection>
</hazelcast>
----
<1> (Required) JDBC URL for establishing a connection to the MySQL database
<2> (Optional) Separate user credentials for authentication. Alternatively, you can include the user credentials in the JDBC URL. 
--

YAML::
+
--
[source,yaml]
----
hazelcast:
  data-connection:
    my-mysql-database:
      type: JDBC
      properties:
        jdbcUrl: jdbc:mysql://mysql.example.org:3306 <1>
        user: my_user <2>
        password: my_password
      shared: true
----
<1> (Required) JDBC URL for establishing a connection to the MySQL database
<2> (Optional) Separate user credentials for authentication. Alternatively, you can include the user credentials in the JDBC URL.
--

Java::
+
--
[source,java]
----
config
  .addDataConnectionConfig(
    new DataConnectionConfig("my-mysql-database")
      .setType("JDBC")
      .setProperty("jdbcUrl", "jdbc:mysql://mysql.example.org:3306") <1>
      .setProperty("user", "my_user") <2>
      .setProperty("password", "my_password")
      .setShared(true)
  );
----
<1> (Required) JDBC URL for establishing a connection to the MySQL database
<2> (Optional) Separate user credentials for authentication. Alternatively, you can include the user credentials in the JDBC URL.
--

SQL::
+
--

Data connections created in SQL behave differently to those defined in members' configuration files or in Java.

- To retain SQL-defined data connections after a cluster restart, you must enable SQL catalog persistence. This feature is available in the Enterprise Edition.
- You can create or drop a data connection using SQL commands. To update a data connection, you need to drop and then recreate it. 

[source,sql]
----
CREATE DATA CONNECTION my_mysql_database
TYPE JDBC
SHARED
OPTIONS (
    'jdbcUrl'='jdbc:mysql://mysql.example.org:3306', <1>
    'user'='my_user', <2>
    'password'='my_password');
----
<1> (Required) JDBC URL for establishing a connection to the MySQL database
<2> (Optional) Separate user credentials for authentication. Alternatively, you can include the user credentials in the JDBC URL.
--
====

[[kafka]]
=== Example Kafka Data Connection

This example shows the configuration of a data connection to a single Kafka broker.

[tabs]
====
XML::
+
--
[source,xml]
----
<hazelcast>
  <data-connection name="my-kafka">
    <type>Kafka</type>
    <properties>
      <property name="bootstrap.servers">127.0.0.1:9092</property> <1>
      <property name="key.deserializer">org.apache.kafka.common.serialization.IntegerDeserializer</property> <2>
      <property name="key.serializer">org.apache.kafka.common.serialization.IntegerSerializer</property>
      <property name="value.serializer">org.apache.kafka.common.serialization.StringSerializer</property>
      <property name="value.deserializer">org.apache.kafka.common.serialization.StringDeserializer</property>
      <property name="auto.offset.reset">earliest</property> <3>
    </properties>
    <shared>true</shared>
  </data-connection>
</hazelcast>
----
<1> (Required) Address of the Kafka consumer/producer  
<2> (Optional) Automatic serializers/deserializers for keys and values in Kafka messages 
<3> (Optional) Consumer behavior if the connection is interrupted
--

YAML::
+
--
[source,yaml]
----
hazelcast:
  data-connection:
    my-kafka:
      type: Kafka
      properties:
        bootstrap.servers: 127.0.0.1:9092 <1>
        key.deserializer: org.apache.kafka.common.serialization.IntegerDeserialize <2> 
        key.serializer: org.apache.kafka.common.serialization.IntegerSerializer
        value.serializer: org.apache.kafka.common.serialization.StringSerializer
        auto.offset.reset: earliest <3>
      shared: true
----
<1> (Required) Address of the Kafka consumer/producer  
<2> (Optional) Automatic serializers/deserializers for keys and values in Kafka messages 
<3> (Optional) Consumer behavior if the connection is interrupted
--

Java::
+
--
[source,java]
----
config
  .addDataConnectionConfig(
    new DataConnectionConfig("my-kafka")
      .setType("Kafka")
      .setProperty("bootstrap.servers", "127.0.0.1:9092") <1>
      .setProperty("key.deserializer", "org.apache.kafka.common.serialization.IntegerDeserialize") <2>
      .setProperty("key.serializer", "org.apache.kafka.common.serialization.IntegerSerializer")
      .setProperty("value.serializer", "org.apache.kafka.common.serialization.StringSerializer")
      .setProperty("auto.offset.reset", "earliest") <3>
      .setShared(true)
  );
----
<1> (Required) Address of the Kafka consumer/producer  
<2> (Optional) Automatic serializers/deserializers for keys and values in Kafka messages 
<3> (Optional) Consumer behavior if the connection is interrupted
--
SQL::
+
--
Data connections created in SQL behave differently to those defined in members' configuration files or in Java.

- To retain SQL-defined data connections after a cluster restart, you must enable SQL catalog persistence. This feature is available in the Enterprise Edition.
- You can create or drop a data connection using SQL commands. To update a data connection, you need to drop and then recreate it. 

[source,sql]
----
CREATE DATA CONNECTION my_kafka
TYPE Kafka
SHARED
OPTIONS (
    'bootstrap.servers'='127.0.0.1:9092', <1>
    'key.deserializer'='org.apache.kafka.common.serialization.IntegerDeserialize', <2>
    'key.serializer'='org.apache.kafka.common.serialization.IntegerSerializer',
    'value.serializer'='org.apache.kafka.common.serialization.StringSerializer',
    'auto.offset.reset'='earliest'); <3>
----
<1> (Required) Address of the Kafka consumer/producer  
<2> (Optional) Automatic serializers/deserializers for keys and values in Kafka messages 
<3> (Optional) Consumer behavior if the connection is interrupted
--
====

[[Mongo]]
=== Example MongoDB Data Connection

This example configuration shows data connections to two MongoDB databases. 

As in the example, you can supply authentication credentials to a MongoDB instance as part of the connection string, or separately. 

[tabs]
====
XML::
+
--
[source,xml]
----
<hazelcast>
  <data-connection name="my-mongodb">
    <type>Mongo</type>
    <properties>
      <property name="connectionString">mongodb://my_user:my_password@some-host:27017</property> <1>
      <property name="database">my_database</property> <2>
    </properties>
    <shared>true</shared>
  </data-connection>
  <data-connection name="my-other-mongodb">
    <type>Mongo</type>
    <properties>
      <property name="host">some_host</property> <3>
      <property name="username">my_user</property> <4>
      <property name="password">my_password</property>
      <property name="database">my_other_database</property> <2>
    </properties>
    <shared>true</shared>
  </data-connection>
</hazelcast>
----
<1> (Required) Connection string of the MongoDB instance, including user credentials  
<2> (Optional) Name of the database to connect to 
<3> (Optional) Host details of the MongoDB instance, excluding user credentials
<4> (Optional) User credentials for the MongoDB instance
--

YAML::
+
--
[source,yaml]
----
hazelcast:
  data-connection:
    my-mongodb:
      type: Mongo
      properties:
        connectionString: mongodb://my_user:my_password@some-host:27017 <1>
        database: my_database <2>
      shared: true
    my-other-mongodb:
      type: Mongo
      properties:
        host: some_host <3>
        username: my_user <4>
        password: my_password
        database: my_other_database <2>
      shared: true
----
<1> (Required) Connection string of the MongoDB instance, including user credentials  
<2> (Optional) Name of the database to connect to 
<3> (Optional) Host details of the MongoDB instance, excluding user credentials
<4> (Optional) User credentials for the MongoDB instance
--

Java::
+
--
[source,java]
----
config
  .addDataConnectionConfig(
    new DataConnectionConfig("my-mongodb")
      .setType("Mongo")
      .setProperty("connectionString", "mongodb://my_user:my_password@some-host:27017") <1>
      .setProperty("database", "my_database") <2>
      .setShared(true)
  )
  .addDataConnectionConfig(
    new DataConnectionConfig("my-other-mongo")
      .setType("Mongo")
      .setProperty("host", "some-host") <3>
      .setProperty("username", "my_user") <4>
      .setProperty("password", "my_password")
      .setProperty("database", "my_other_database") <2>
      .setShared(true)
  );
----
<1> (Required) Connection string of the MongoDB instance, including user credentials  
<2> (Optional) Name of the database to connect to 
<3> (Required) Host details of the MongoDB instance, excluding user credentials
<4> (Optional) User credentials for the MongoDB instance
--
SQL::
+
--
Data connections created in SQL behave differently to those defined in members' configuration files or in Java.

- To retain SQL-defined data connections after a cluster restart, you must enable SQL catalog persistence. This feature is available in the Enterprise Edition.
- You can create or drop a data connection using SQL commands. To update a data connection, you need to drop and then recreate it. 

[source,SQL]
----
CREATE DATA CONNECTION my_mongodb
TYPE Mongo
SHARED
OPTIONS (
    'connectionString'='mongodb://my_user:my_password@some-host:27017', <1>
    'database'='my_database'); <2>
----
<1> (Required) Connection string of the MongoDB instance, including user credentials  
<2> (Optional) Name of the database to connect to 

[source,SQL]
----
CREATE DATA CONNECTION my_mongodb
TYPE Mongo
SHARED
OPTIONS (
    'host'='some-host', <1>
    'username'='my_user', <2>
    'password'='my_password'
    'database'='my_other_database');
----
<1> (Required) Host details of the MongoDB instance, excluding user credentials
<2> (Optional) User credentials for the MongoDB instance
--
====

[[configuration-options]]
== Configuration Options for Data Connections

Data connections have the following configuration options.

NOTE: If you are using Java to configure the Mapstore, use the link:https://docs.hazelcast.org/docs/{full-version}/javadoc/com/hazelcast/config/DataConnectionConfig.html[`DataConnectionConfig` object].

.Data connection configuration options
[cols="1a,1a",options="header"]
|===
|Option|Description|Default|Example

|`name` (required)
|The unique identifier for the data connection.

|`type` (required)
|The type of data connection required for your external system. The following types of connection are supported: `JDBC`, `Kafka`,`Mongo`(case-insensitive).

|`properties`
|Any configuration properties that the data connection expects to receive.

|`shared`
|Whether the data connection instance is reusable in different MapStores, jobs, and SQL mappings. This behavior depends on the implementation of the specific data connection. The default value is `true`. See the implementation of each data connection type for full details of reusability: link:https://docs.hazelcast.org/docs/{full-version}/javadoc/com/hazelcast/dataconnection/HazelcastDataConnection.html[`HazelcastDataConnection`], link:https://docs.hazelcast.org/docs/{full-version}/javadoc/com/hazelcast/jet/kafka/KafkaDataConnection.html[`KafkaDataConnection`], link:https://docs.hazelcast.org/docs/{full-version}/javadoc/com/hazelcast/jet/mongodb/dataconnection/MongoDataConnection.html[`MongoDataConnection`].

|===

[[connectors]]
== Types of Data Connection

The following types of data connection are available for use. 

[cols="1a,1a,1a",options="header"]
|===
|Type|Description|Properties

|`JDBC`
|Connect to external systems that support JDBC, including MySQL and PostgreSQL.
|For available configuration properties see link:https://github.com/brettwooldridge/HikariCP#gear-configuration-knobs-baby[HikariCP configuration]. This implementation is based on link:https://github.com/brettwooldridge/HikariCP[HikariDataSource]. All properties are passed directly to `HikariConfig`. 

If there is more than one JDBC connection used on a single member from a single job, they will share the same data store and connection pool.

|`Kafka`
|Connect to a Kafka data source.
|See <<kafka, example>> and xref:sql:mapping-to-kafka.adoc#creating-a-kafka-mapping[Create a Kafka Mapping].

|`Mongo`
|Connect to a MongoDB database.
|See <<Mongo, example>>.

|===

NOTE: If you use the slim distribution of Hazelcast with a built-in data connector, make sure that you have an appropriate driver on your cluster's classpath.

== Related Resources

You can also add new data connections dynamically at runtime, see xref:configuration:dynamic-config.adoc[dynamic configuration].

== Next Steps

Use your configured connection:

- Build a data pipeline with the xref:integrate:jdbc-connector.adoc[Pipeline API].
- Query your data connection, using a xref:sql:mapping-to-jdbc.adoc[SQL mapping].
- Build a cache with a xref:mapstore:configuring-a-generic-mapstore.adoc[MapStore].
